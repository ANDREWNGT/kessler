{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "covered-tradition",
   "metadata": {},
   "source": [
    "## LSTM training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-bicycle",
   "metadata": {},
   "source": [
    "In this tutorial, we train a recurrent neural network architecture (i.e., a stack of Bayesian LSTMs) on CDMs data, and use it for prediction purposes.\n",
    "\n",
    "\n",
    "We assume that data have already been loaded (either from ``.kvn`` format, from pandas ``DataFrame`` object, or from the Kelvins challenge dataset: see the relevant tutorials) and stored into ``events``.\n",
    "We can then first define the features that have to be taken into account during training: this is a list of feature names. In this case, we can take all the features present on the uploaded data, provided that they have numeric content:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_features=events.common_features(only_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-spectacular",
   "metadata": {},
   "source": [
    "We can then split the data into test (here defined as 5% of the total number of events) and training & validation set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test_set=int(0.05*len(events))\n",
    "events_test=events[-len_test_set:]\n",
    "events_train_and_val=events[:-len_test_set]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-recording",
   "metadata": {},
   "source": [
    "Finally, we create the LSTM predictor, by defining the LSTM hyperparameters as we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kessler.nn import LSTMPredictor\n",
    "model = LSTMPredictor(\n",
    "           lstm_size=256, #number of hidden units per LSTM layer\n",
    "           lstm_dept=2,   #number of stacked LSTM layers\n",
    "           dropout=0.2,   #dropout probability\n",
    "           features=nn_features) #the list of feature names to use in the LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-helen",
   "metadata": {},
   "source": [
    "Then we start the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(events_train_and_val,\n",
    "           epochs=10, #number of epochs\n",
    "           lr=1e-3, #learning rate (can decrease if training diverges)\n",
    "           batch_size=16, #minibatch size (can decrease if there are memory issues)\n",
    "           device='cpu', #can be 'cuda' if there is a GPU available\n",
    "           valid_proportion=0.15, #proportion of data used as validation set\n",
    "           num_workers=4, #number of multithreaded dataloader workers (usually 4 is good for performances, but if there are issues, try 1)\n",
    "           event_samples_for_stats=1000) #number of events to use to compute NN normalization factors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-chicago",
   "metadata": {},
   "source": [
    "Finally, we save the model to a file after training, and we plot the validation and training loss and save the image to a file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(file_name='LSTM_20epochs_lr1e-4_batchsize16')\n",
    "model.plot_loss(file_name='plot_loss.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-genealogy",
   "metadata": {},
   "source": [
    "We now test the prediction. We take a single event, we remove the last CDM and try to predict it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "event=events_test[3]\n",
    "event_len=len(event)\n",
    "event_beginning=event[0:event_len-1]\n",
    "event_evolution=model.predict_event(event_beginning, num_samples=100, max_length=14)\n",
    "#we plot the prediction in red:\n",
    "axs=event_evolution.plot_features(['RELATIVE_SPEED', 'MISS_DISTANCE'], return_axs=True, linewidth=0.1, color='red', alpha=0.33, label='Prediction')\n",
    "#and the ground truth value in blue:\n",
    "event.plot_features(['RELATIVE_SPEED', 'MISS_DISTANCE'], axs=axs, label='Real', legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
